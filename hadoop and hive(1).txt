1. Download hive tar gz file in hdp123 user
https://downloads.apache.org/hive/hive-2.3.9/apache-hive-2.3.9-bin.tar.gz

su hdp123 (after this command do not change directory and execute next command immediately)
tar -xvzf apache-hive-2.3.9-bin.tar.gz
sudo mv apache-hive-2.3.9-bin /home/hdp123/apache
cd

2. sudo nano ~/.bashrc 
export HIVE_HOME=/home/hdp123/apache-hive-2.3.9-bin
export PATH=$PATH:$HIVE_HOME/bin
export HIVE_CONF_DIR=/home/hdp123/apache-hive-2.3.9-bin/conf

3. source ~/.bashrc

4. Go to Hive folder and rename "hive-default.xml.template" as
"hive-default.xml" & "hive-env.sh.template" as "hive-env.sh"
cd apache/conf
sudo mv hive-default.xml.template hive-site.xml
sudo mv hive-env.sh.template hive-env.sh


5. sudo nano hive-env.sh
export HADOOP_HOME=/usr/local/hadoop

7. Create 2 folders :

a. start-all.sh
b. sudo chown -R hdp123 /home/hdp123/apache/
c. user/hive/warehouse - To store hive tables
cd $HADOOP_HOME
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod 777 /user/hive/warehouse

d. tmp - to store temporary information 
cd $HADOOP_HOME
hdfs dfs -mkdir -p /tmp
hdfs dfs -chmod 777 /tmp

8. Configuring metastore
cd $HIVE_HOME/bin
schematool -dbType derby -initSchema


8. hive

------------------------------------------------------------
------------------------------------------------------------

RUNNING HIVE QUERIES 


show databases;

create database dypcoe;

create table emp(ename string,esal int) row format delimited fields terminated by '_'stored as textfile;

load data local inpath '/home/hdp123/files/sample.txt' into table emp;

select * from emp;

create table flight(Year int, Month int, DayofMonth int, DayOfWeek int, DepTime  int, CRSDepTime int, ArrTime int, CRSArrTime int, UniqueCarrier string, FlightNum int, TailNum string, ActualElapsedTime int, CRSElapsedTime int, AirTime int, ArrDelay int, DepDelay int, Origin string, Dest string, Distance int, TaxiIn int, TaxiOut int, Cancelled int, CancellationCode string, Diverted string, CarrierDelay int, WeatherDelay int, NASDelay int,  SecurityDelay int, LateAircraftDelay int) row format delimited fields terminated by ',';

load data local inpath '/home/hdp123/files/flight_data.csv' into table flight;

hdfs dfs -mkdir /user/hive/flight
hdfs dfs -put /home/hdp123/files/flight_ext.csv /user/hive/flight
hdfs dfs -ls /user/hive/flight

create external table flight_ext(Year int, Month int, DayofMonth int, DayOfWeek int, DepTime  int, CRSDepTime int, ArrTime int, CRSArrTime int, UniqueCarrier string, FlightNum int, TailNum string, ActualElapsedTime int, CRSElapsedTime int, AirTime int, ArrDelay int, DepDelay int, Origin string, Dest string, Distance int, TaxiIn int, TaxiOut int, Cancelled int, CancellationCode string, Diverted string, CarrierDelay int, WeatherDelay int, NASDelay int,  SecurityDelay int, LateAircraftDelay int) row format delimited fields terminated by ',' location '/user/hive/flight';

describe formatted flight;

select count(*) from flight_ext;

create table flight_fare( FlightNum int,  Fare int) row format delimited fields terminated by ',';

load data local inpath '/home/hdp123/files/flight_fare.csv' into table flight_fare;

select flight.Origin, flight.Dest, flight_fare.fare from flight join flight_fare on flight.FlightNum=flight_fare.FlightNum;

select avg(depdelay) from flight;